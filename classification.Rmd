---
title: "classification"
author: "cshb26"
date: "3/19/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
install.packages("infotheo") #分箱
install.packages("caret")
install.packages("mlr3verse")
```

```{r}
library("tidyverse")
library("ggplot2")
library("GGally")
library("infotheo")
library("caret")
library("data.table")
library("mlr3verse")
```


## Problem Description

### Description of the data and the explanation of the objective of the analysis

```{r}
hotels0 = readr::read_csv("https://www.louisaslett.com/Courses/MISCADA/hotels.csv")
```

```{r}
View(hotels0)
```

### Initial data summary

```{r}
skimr::skim(hotels0)
```

### Simple visualisations of the data
```{r}
ggplot(hotels0 %>%
         filter(adr < 4000) %>% 
         mutate(total_nights = stays_in_weekend_nights+stays_in_week_nights),
       aes(x = adr, y = total_nights)) +
  geom_point(alpha=0.1)
```


```{r}
DataExplorer::plot_bar(hotels0, by = "is_canceled", ncol = 2)
```

```{r}
DataExplorer::plot_boxplot(hotels0, by = "is_canceled", ncol = 3)
```



## Model fitting

### 数据清洗
#### 删除冗余特征及非相关变量：
1. Drop `reservation_status` and `reservation_status_date`
2. 同时设置total_nights变量取代两个stays (Drop `stay`)
3. 同时设置kids变量取代children和babies (Drop `children` and `babies`)
4. reserved_room_type和assigned_room_type一致为1，不一致为0
5. create a new variable called parking which is either “parking” or “none” depending on the required_car_parking_spaces variable value
6. 将月份转换为factor
7. country、agent、company、日期和周数类别过多，不做考虑
```{r}
hotels1 <- hotels0 %>%
  mutate(total_nights = stays_in_weekend_nights+stays_in_week_nights) %>% 
  mutate(kids = case_when(children + babies > 0 ~ "kids", TRUE ~ "none")) %>%
  mutate(room_type = case_when(reserved_room_type == assigned_room_type ~ 1, TRUE ~ 0)) %>% 
  mutate(parking = case_when(required_car_parking_spaces > 0 ~ "parking", TRUE ~ "none")) %>% 
  mutate(arrival_date_month = as.integer(match(substr(arrival_date_month,1,3), month.abb)))

hotels2 <- hotels1 %>%
  select(-reservation_status, -reservation_status_date, -stays_in_weekend_nights, -stays_in_week_nights, -children, -babies, -reserved_room_type, -assigned_room_type, -required_car_parking_spaces, -country, -agent, -company, -arrival_date_year, -arrival_date_month, -arrival_date_day_of_month, -arrival_date_week_number)
```

```{r}
skimr::skim(hotels2)
```

#### 对剩余变量进行相关度分析
```{r}
ggpairs(hotels2 %>% select(hotel, meal, market_segment, distribution_channel, deposit_type, customer_type, kids, parking, adr, adults, is_canceled), aes(color = kids))
```


```{r}
ggpairs(hotels2 %>% select(kids, lead_time, is_repeated_guest, previous_cancellations, previous_bookings_not_canceled, previous_bookings_not_canceled, booking_changes, days_in_waiting_list, total_of_special_requests, total_nights, room_type, is_canceled), aes(color = kids))
```

根据图像(ggpairs或dataexplorer)删除几个特征
```{r}
hotels3 <- hotels2 %>% 
  select(-hotel, -meal, -market_segment, -distribution_channel, -kids, -parking, -adr, -total_nights)
```
```{r}
skimr::skim(hotels3)
```

#### 处理异常值
1. days_in_waiting_list 99%的人都是0，不具有代表性，故删除

```{r}
ggplot(hotels3, aes(x = days_in_waiting_list)) + geom_bar()
```

```{r}
hotels4 <- hotels3 %>% group_by(days_in_waiting_list) %>% count(days_in_waiting_list)
hotels4 %>% mutate(prop = n/119390)
```

```{r}
hotels4 <- hotels3 %>% select(-days_in_waiting_list)
```

```{r}
skimr::skim(hotels4)
```

2. lead_time 值较多，故对其进行分箱操作

```{r}
hotels4 %>% group_by(lead_time) %>% summarise(prop = mean(is_canceled)) %>% ggplot(aes(x=lead_time, y=prop))+
geom_bar(stat='identity', width=2)
```

```{r}
equal_freq_data <- discretize(hotels4$lead_time, 'equalfreq', 4) #等频分箱操作
table(equal_freq_data) #查看各分类数量
```

```{r}
sort_data <- hotels4$lead_time[order(hotels4$lead_time)] #对数据进行排序
depreciation <- as.data.frame(table(equal_freq_data))
depreciation
```
```{r}
sort_data[30260]
sort_data[30260+29639]
sort_data[30260+29639+29669]
sort_data[30260+29639+29669+29822]
```

循环更改lead_time的值
```{r}
hotels <- hotels4 %>%
  mutate(lead_time = case_when(lead_time>160 ~ 4, lead_time>69 & lead_time<=160 ~ 3, lead_time>18 & lead_time<=69 ~ 2, TRUE ~ 1))
```

```{r}
skimr::skim(hotels)
```

```{r}
View(hotels)
```

### any train/test/validate, cross-validation, nested resampling or bootstrap strategies employed

```{r}
fit.lr <- glm(as.factor(is_canceled) ~ ., binomial, hotels)
```

```{r}
pred.lr <- predict(fit.lr, hotels, type = "response")
ggplot(data.frame(x = pred.lr), aes(x = x)) + geom_histogram()
```

```{r}
conf.mat <- table(`canceled` = hotels$is_canceled, `predict cancel` = pred.lr > 0.5)
conf.mat
conf.mat/rowSums(conf.mat)*100
```

```{r}
skimr::skim(hotels)
```

## 加入超参数
```{r}
fit.lr <- glm(as.factor(is_canceled) ~ ., binomial, hotels, epsilon = 1e-5)
summary(fit.lr)
```

```{r}
conf.mat <- table(`canceled` = hotels$is_canceled, `predict cancel` = pred.lr > 0.5)
conf.mat
conf.mat/rowSums(conf.mat)*100
```




采用交叉验证

### 交叉验证前处理

```{r}
hotels <- hotels %>% select(-customer_type, -adults)
hotels$deposit_type <- factor(hotels$deposit_type, levels=c("No Deposit", "Non Refund", "Refundable"), ordered = TRUE)
hotels$is_canceled <- factor(hotels$is_canceled, levels=c("0", "1"), ordered = TRUE)
```
```{r}
hotels$lead_time <- factor(hotels$lead_time)
hotels$is_repeated_guest <- factor(hotels$is_repeated_guest)
hotels$previous_cancellations <- factor(hotels$previous_cancellations)
hotels$previous_bookings_not_canceled <- factor(hotels$previous_bookings_not_canceled)
hotels$booking_changes <- factor(hotels$booking_changes)
hotels$total_of_special_requests <- factor(hotels$total_of_special_requests)
hotels$room_type <- factor(hotels$room_type)
```


```{r}
library("mlr3learners")
library("mlr3proba")
library("data.table")
library("mlr3verse")
```


```{r}
set.seed(26)
hotels_task <- TaskClassif$new(id = "hotels", backend = na.omit(hotels), target = "is_canceled")

cv5 <- rsmp("cv", folds = 5)
cv5$instantiate(hotels_task)
```

```{r}
lrn_cart_cv <- lrn("classif.rpart", predict_type = "prob", xval = 10)

res_cart_cv <- resample(hotels_task, lrn_cart_cv, cv5, store_models = TRUE)
rpart::plotcp(res_cart_cv$learners[[5]]$model)
```
### 交叉验证结束

```{r}
skimr::skim(hotels)
```


## Model improvements

```{r}
lrnsp_log_reg <- lrn("classif.log_reg", predict_type = "prob", id = "super")

# Missingness imputation pipeline
pl_missing <- po("fixfactors") %>>%
  po("removeconstants") %>>%
  po("imputesample", affect_columns = selector_type(c("ordered", "factor"))) %>>%
  po("imputemean")

# Factors coding pipeline
pl_factor <- po("encode")

# Now define the full pipeline
spr_lrn <- gunion(list(
  # First group of learners requiring no modification to input
  gunion(list(
    po("learner_cv", lrn_baseline),
    po("learner_cv", lrn_cart),
    po("learner_cv", lrn_cart_cp)
  )),
  # Next group of learners requiring special treatment of missingness
  pl_missing %>>%
    gunion(list(
      po("learner_cv", lrn_ranger),
      po("learner_cv", lrn_log_reg),
      po("nop") # This passes through the original features adjusted for
                # missingness to the super learner
    )),
  # Last group needing factor encoding
  pl_factor %>>%
    po("learner_cv", lrn_xgboost)
)) %>>%
  po("featureunion") %>>%
  po(lrnsp_log_reg)

# This plot shows a graph of the learning pipeline
spr_lrn$plot()

# Finally fit the base learners and super learner and evaluate
res_spr <- resample(hotels_task, spr_lrn, cv5, store_models = TRUE)
res_spr$aggregate(list(msr("classif.ce"),
                       msr("classif.acc"),
                       msr("classif.fpr"),
                       msr("classif.fnr")))
```

### 逻辑回归 improve

```{r}
search_space = ps(
  epsilon = p_dbl(lower = 1e-15, upper = 1e-05),
  maxit = p_int(lower = 1, upper = 30)
)
search_space

measures = msrs(c("classif.acc", "time_train"))
library("mlr3tuning")

evals20 = trm("evals", n_evals = 20)

instance = TuningInstanceMultiCrit$new(
  task = hotels_task,
  learner = lrn_log_reg ,
  resampling = rsmp("holdout"),
  measures = measures,
  search_space = search_space,
  terminator = evals20
)
instance

#tuner=tnr("random_search")
tuner = tnr("grid_search", resolution = 5)
tuner$optimize(instance)
instance$result_y
instance$result_learner_param_vals
```













### Super learner
```{r}
lb <- lrn("classif.featureless", predict_type = "prob")
lc <- lrn("classif.rpart", predict_type = "prob")
```
```{r}
lrn_cart_cp  <- lrn("classif.rpart", predict_type = "prob", cp = 0.025, id = "cartcp")
lrn_ranger   <- lrn("classif.ranger", predict_type = "prob")
lrn_xgboost  <- lrn("classif.xgboost", predict_type = "prob")
```

```{r}
hotels_res <- benchmark(data.table(
  task       = list(hotels_task),
  learner    = list(lb,
                    lc,
                    lrn_cart_cp,
                    
                    pl_log_reg),
  resampling = list(cv5)
), store_models = TRUE)

hotels_res$aggregate(list(msr("classif.ce"),
                   msr("classif.acc"),
                   msr("classif.fpr"),
                   msr("classif.fnr")))
```


```{r}
lrnsp_log_reg <- lrn("classif.log_reg", predict_type = "prob", id = "super")

# Factors coding pipeline
pl_factor <- po("encode")

# Now define the full pipeline
spr_lrn <- gunion(list(
  # First group of learners requiring no modification to input
  gunion(list(
    po("learner_cv", lb),
    po("learner_cv", lc),
    po("learner_cv", lrn_cart_cp)
  )),
  # Next group of learners requiring special treatment of missingness
  pl_missing %>>%
    gunion(list(
      po("learner_cv", lrn_ranger),
      po("learner_cv", lrn_log_reg),
      po("nop") # This passes through the original features adjusted for
                # missingness to the super learner
    )),
  # Last group needing factor encoding
  pl_factor %>>%
    po("learner_cv", lrn_xgboost)
)) %>>%
  po("featureunion") %>>%
  po(lrnsp_log_reg)

# This plot shows a graph of the learning pipeline
spr_lrn$plot()

# Finally fit the base learners and super learner and evaluate
res_spr <- resample(hotels_task, spr_lrn, cv5, store_models = TRUE)
res_spr$aggregate(list(msr("classif.ce"),
                       msr("classif.acc"),
                       msr("classif.fpr"),
                       msr("classif.fnr")))
```



```{r}
N = length(hotels$is_canceled)                                                 
#ind=1的是0.7概率出现的行，ind=2是0.3概率出现的行
ind=sample(2,N,replace=TRUE,prob=c(0.7,0.3))
#生成训练集(这里训练集和测试集随机设置为原数据集的70%，30%)
hotel_train <- hotels[ind==1,]
#生成测试集
hotel_test <- hotels[ind==2,]
```
```{r}
#生成模型，用glm函数
#用训练集数据生成logis模型，用glm函数
#family：每一种响应分布（指数分布族）允许各种关联函数将均值和线性预测器关联起来。常用的family：binomal(link='logit')--响应变量服从二项分布，连接函数为logit，即logistic回归
pre <- glm(is_canceled ~., family=binomial(link="logit"), data=hotel_train)
summary(pre)
 
#测试集的真实值
real <- hotel_test$is_canceled
#predict函数可以获得模型的预测值。这里预测所需的模型对象为pre，预测对象newdata为测试集,预测所需类型type选择response,对响应变量的区间进行调整
predict. <- predict.glm(pre, type='response', newdata=hotel_test)
#按照预测值为1的概率，>0.5的返回1，其余返回0
```

```{r}
##模型检验
# res <- data.frame(real, predict)
#训练数据的行数，也就是样本数量
n = nrow(hotel_train)      
#计算Cox-Snell拟合优度
R2 <- 1-exp((pre$deviance-pre$null.deviance)/n)    
cat("Cox-Snell R2=",R2,"\n")
#计算Nagelkerke拟合优度，我们在最后输出这个拟合优度值
R2<-R2/(1-exp((-pre$null.deviance)/n))  
cat("Nagelkerke R2=",R2,"\n")
```
```{r}
true_value = hotels$is_canceled
predict_value = predict.
#计算模型精确度
error = predict_value-true_value
accuracy = (nrow(hotel_test)-sum(abs(error)))/nrow(hotel_test) #精确度--判断正确的数量占总数的比例
#计算Precision，Recall和F-measure
#一般来说，Precision就是检索出来的条目（比如：文档、网页等）有多少是准确的，Recall就是所有准确的条目有多少被检索出来了
#和混淆矩阵结合，Precision计算的是所有被检索到的item（TP+FP）中,"应该被检索到的item（TP）”占的比例；Recall计算的是所有检索到的item（TP）占所有"应该被检索到的item（TP+FN）"的比例。
precision=sum(true_value & predict_value)/sum(predict_value)  #真实值预测值全为1 / 预测值全为1 --- 提取出的正确信息条数/提取出的信息条数
recall=sum(predict_value & true_value)/sum(true_value)  #真实值预测值全为1 / 真实值全为1 --- 提取出的正确信息条数 /样本中的信息条数
#P和R指标有时候会出现的矛盾的情况，这样就需要综合考虑他们，最常见的方法就是F-Measure（又称为F-Score）
F_measure=2*precision*recall/(precision+recall)    #F-Measure是Precision和Recall加权调和平均，是一个综合评价指标
#输出以上各结果
print(accuracy)
print(precision)
print(recall)
print(F_measure)
```
```{r}
library(pROC)
modelroc <- roc(true_value, predict.)
plot(modelroc, print.auc=TRUE, auc.polygon=TRUE,legacy.axes=TRUE, grid=c(0.1, 0.2),
     grid.col=c("green", "red"), max.auc.polygon=TRUE,
     auc.polygon.col="skyblue", print.thres=TRUE)        #画出ROC曲线，标出坐标，并标出AUC
```


## Performance report

### details on the performance of the model, including calibration



### reporting and justification of objective function choices



### would you be more worried about false negatives or false positives in this problem, and how could you address that concern

